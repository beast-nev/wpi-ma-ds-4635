SVC:
    OLD FE:
        'shrinking': True, 'probability': False, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 1.0,
        'decision_function_shape': 'ovr', 'cache_size': 579.5918367346939, 'break_ties': False, 'C': 1.0

        With k=6 best
        if_classif
        Accuracies:  0.6365735885830673
        Test train split score:  0.6236683352586317
        mutal_class_if
        Accuracies:  0.6498319721930927
        Test train split score:  0.6438197920677705

        With no kbest
        Accuracies:  0.6643562389251304
        Test train split score:  0.6563984084199718

        Without k best
        Accuracies:  0.6643562389251304
        Test train split score:  0.6563984084199718

    New FE:
        SelectKBest(k=26), Bagging(ovr(SVC))
        Accuracy:  0.6087102102520806
        kernel:
            linear:
                Accuracy:  0.6490669867388767
            poly
                Accuracy:  0.523798320095547
            rbf:
                Accuracy:  0.716342535211602
            sigmoid:
                Accuracy:  0.5395111432950074
        No ovr: kernel=rbf
            Accuracy:  0.7110290972219337
        
        Forward Subset Selection:
            
                

NCA KNN:
    Accuracy:  0.6307277628032345

Bagging KNN: (cv=10) // SelectKBest(k=60), max_samples=0.3, max_features=0.5
    mutal_class_if:
        Accuracy:  0.696895923529164 (k=1)
        Accuracy:  0.7211950882047733 (k=3)
        Accuracy:  0.7248924918108071 (k=5) <- best
        Accuracy:  0.7196931774425035 (k=10)
        Accuracy:  0.7128005794287945 (k=15)
    if_classif:
        Accuracy:  0.7076783363285717 (k=1)
        Accuracy:  0.7293579975235145 (k=3)
        Accuracy:  0.7310147479639004 (k=5) <- best
        Accuracy:  0.7282808390385257 (k=10)
        Accuracy:  0.7225433459135318 (k=15)
    SelectKBest(k=30) // if_classif (knn=5)
        Accuracy:  0.7579326151485684
    SelectKBest(k=15) // if_classif (knn=5)
        Accuracy:  0.7230427962096837
    SelectKBest(k=23) // if_classif (knn=5)
        Accuracy:  0.7534277579974049
    SelectKBest(k=26) // if_classif (knn=5)
        Accuracy:  0.7582792430284322 <--- best cv but lowest test score on kaggle

Boosting (SelectKBest(k=26)):
    Accuracy:  0.781423406644979
    
    {'n_estimators': 300, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 9, 'loss': 'deviance', 'learning_rate': 1, 'criterion': 'friedman_mse'}
    0.8031807279444703

    {'n_estimators': 300, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 9, 'loss': 'exponential', 'criterion': 'friedman_mse'}
    0.8099197840521819

    Accuracy:  0.8270178403076205 (SelectKBest(k=64))

    Features chosen:  ['sensor_02_std', 'sensor_02_max', 'sensor_04_mean']
    Accuracy:  0.7325552091930181

RF:
    feature selection
    selector = SelectKBest(mutual_info_classif, k=6)
    x_train = selector.fit_transform(x_train, y_train.values.ravel())

    if_classif
    Accuracies:  0.6850963844665071
    Test train split score:  0.6733410345270183

    mustal_class_if
    Accuracies:  0.6935688658274356
    Test train split score:  0.6920806058272365

Logistic Regression
    Accuracy:  0.5480976775976549
